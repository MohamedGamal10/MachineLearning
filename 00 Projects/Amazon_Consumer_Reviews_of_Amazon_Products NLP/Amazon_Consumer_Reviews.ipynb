{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a list of over 34,000 consumer reviews for Amazon products like the Kindle, Fire TV Stick, and more provided by Datafiniti's Product Database. The dataset includes basic product information, rating, review text, and more for each product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Mohamed\n",
      "[nltk_data]     Gamal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Mohamed\n",
      "[nltk_data]     Gamal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Mohamed Gamal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Mohamed\n",
      "[nltk_data]     Gamal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import re, string\n",
    "import warnings\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('1429_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 21\n",
      "Number of samples: 34660\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of features: {}\".format(dataset.shape[1]))\n",
    "print(\"Number of samples: {}\".format(dataset.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>asins</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>keys</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>reviews.date</th>\n",
       "      <th>reviews.dateAdded</th>\n",
       "      <th>reviews.dateSeen</th>\n",
       "      <th>...</th>\n",
       "      <th>reviews.doRecommend</th>\n",
       "      <th>reviews.id</th>\n",
       "      <th>reviews.numHelpful</th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>reviews.sourceURLs</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.title</th>\n",
       "      <th>reviews.userCity</th>\n",
       "      <th>reviews.userProvince</th>\n",
       "      <th>reviews.username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AVqkIhwDv8e3D1O-lebb</td>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>B01AHB9CN2</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "      <td>841667104676,amazon/53004484,amazon/b01ahb9cn2...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>2017-01-13T00:00:00.000Z</td>\n",
       "      <td>2017-07-03T23:33:15Z</td>\n",
       "      <td>2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>http://reviews.bestbuy.com/3545/5620406/review...</td>\n",
       "      <td>This product so far has not disappointed. My c...</td>\n",
       "      <td>Kindle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adapter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AVqkIhwDv8e3D1O-lebb</td>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>B01AHB9CN2</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "      <td>841667104676,amazon/53004484,amazon/b01ahb9cn2...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>2017-01-13T00:00:00.000Z</td>\n",
       "      <td>2017-07-03T23:33:15Z</td>\n",
       "      <td>2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>http://reviews.bestbuy.com/3545/5620406/review...</td>\n",
       "      <td>great for beginner or experienced person. Boug...</td>\n",
       "      <td>very fast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AVqkIhwDv8e3D1O-lebb</td>\n",
       "      <td>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...</td>\n",
       "      <td>B01AHB9CN2</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Electronics,iPad &amp; Tablets,All Tablets,Fire Ta...</td>\n",
       "      <td>841667104676,amazon/53004484,amazon/b01ahb9cn2...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>2017-01-13T00:00:00.000Z</td>\n",
       "      <td>2017-07-03T23:33:15Z</td>\n",
       "      <td>2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>http://reviews.bestbuy.com/3545/5620406/review...</td>\n",
       "      <td>Inexpensive tablet for him to use and learn on...</td>\n",
       "      <td>Beginner tablet for our 9 year old son.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DaveZ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                               name  \\\n",
       "0  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
       "1  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
       "2  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
       "\n",
       "        asins   brand                                         categories  \\\n",
       "0  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
       "1  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
       "2  B01AHB9CN2  Amazon  Electronics,iPad & Tablets,All Tablets,Fire Ta...   \n",
       "\n",
       "                                                keys manufacturer  \\\n",
       "0  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
       "1  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
       "2  841667104676,amazon/53004484,amazon/b01ahb9cn2...       Amazon   \n",
       "\n",
       "               reviews.date     reviews.dateAdded  \\\n",
       "0  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
       "1  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
       "2  2017-01-13T00:00:00.000Z  2017-07-03T23:33:15Z   \n",
       "\n",
       "                                    reviews.dateSeen  ... reviews.doRecommend  \\\n",
       "0  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
       "1  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
       "2  2017-06-07T09:04:00.000Z,2017-04-30T00:45:00.000Z  ...                True   \n",
       "\n",
       "  reviews.id  reviews.numHelpful  reviews.rating  \\\n",
       "0        NaN                 0.0             5.0   \n",
       "1        NaN                 0.0             5.0   \n",
       "2        NaN                 0.0             5.0   \n",
       "\n",
       "                                  reviews.sourceURLs  \\\n",
       "0  http://reviews.bestbuy.com/3545/5620406/review...   \n",
       "1  http://reviews.bestbuy.com/3545/5620406/review...   \n",
       "2  http://reviews.bestbuy.com/3545/5620406/review...   \n",
       "\n",
       "                                        reviews.text  \\\n",
       "0  This product so far has not disappointed. My c...   \n",
       "1  great for beginner or experienced person. Boug...   \n",
       "2  Inexpensive tablet for him to use and learn on...   \n",
       "\n",
       "                             reviews.title reviews.userCity  \\\n",
       "0                                   Kindle              NaN   \n",
       "1                                very fast              NaN   \n",
       "2  Beginner tablet for our 9 year old son.              NaN   \n",
       "\n",
       "   reviews.userProvince  reviews.username  \n",
       "0                   NaN           Adapter  \n",
       "1                   NaN            truman  \n",
       "2                   NaN             DaveZ  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'asins', 'brand', 'categories', 'keys', 'manufacturer',\n",
       "       'reviews.date', 'reviews.dateAdded', 'reviews.dateSeen',\n",
       "       'reviews.didPurchase', 'reviews.doRecommend', 'reviews.id',\n",
       "       'reviews.numHelpful', 'reviews.rating', 'reviews.sourceURLs',\n",
       "       'reviews.text', 'reviews.title', 'reviews.userCity',\n",
       "       'reviews.userProvince', 'reviews.username'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34660 entries, 0 to 34659\n",
      "Data columns (total 21 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   id                    34660 non-null  object \n",
      " 1   name                  27900 non-null  object \n",
      " 2   asins                 34658 non-null  object \n",
      " 3   brand                 34660 non-null  object \n",
      " 4   categories            34660 non-null  object \n",
      " 5   keys                  34660 non-null  object \n",
      " 6   manufacturer          34660 non-null  object \n",
      " 7   reviews.date          34621 non-null  object \n",
      " 8   reviews.dateAdded     24039 non-null  object \n",
      " 9   reviews.dateSeen      34660 non-null  object \n",
      " 10  reviews.didPurchase   1 non-null      object \n",
      " 11  reviews.doRecommend   34066 non-null  object \n",
      " 12  reviews.id            1 non-null      float64\n",
      " 13  reviews.numHelpful    34131 non-null  float64\n",
      " 14  reviews.rating        34627 non-null  float64\n",
      " 15  reviews.sourceURLs    34660 non-null  object \n",
      " 16  reviews.text          34659 non-null  object \n",
      " 17  reviews.title         34655 non-null  object \n",
      " 18  reviews.userCity      0 non-null      float64\n",
      " 19  reviews.userProvince  0 non-null      float64\n",
      " 20  reviews.username      34658 non-null  object \n",
      "dtypes: float64(5), object(16)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From above dataset we choose two columns 'reviews.text' , 'reviews.rating' for NLP job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset[['reviews.text','reviews.rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This product so far has not disappointed. My c...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great for beginner or experienced person. Boug...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inexpensive tablet for him to use and learn on...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've had my Fire HD 8 two weeks now and I love...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I bought this for my grand daughter when she c...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        reviews.text  reviews.rating\n",
       "0  This product so far has not disappointed. My c...             5.0\n",
       "1  great for beginner or experienced person. Boug...             5.0\n",
       "2  Inexpensive tablet for him to use and learn on...             5.0\n",
       "3  I've had my Fire HD 8 two weeks now and I love...             4.0\n",
       "4  I bought this for my grand daughter when she c...             5.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>reviews.rating</th>\n",
       "      <td>33</td>\n",
       "      <td>0.000952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.text</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Total   Percent\n",
       "reviews.rating     33  0.000952\n",
       "reviews.text        1  0.000029"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = df.isnull().sum().sort_values(ascending=False)\n",
    "percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>reviews.rating</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.text</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Total  Percent\n",
       "reviews.rating      0      0.0\n",
       "reviews.text        0      0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = df.isnull().sum().sort_values(ascending=False)\n",
    "percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df.iloc[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this product so far has not disappointed. my children love to use it and i like the ability to monitor control what content they see with ease.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = str(sample).lower()\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Strip white space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this product so far has not disappointed. my children love to use it and i like the ability to monitor control what content they see with ease.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = str(sample).strip()\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove HTML tags/markups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this product so far has not disappointed. my children love to use it and i like the ability to monitor control what content they see with ease.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = re.compile('<.*?>').sub('', str(sample))\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this product so far has not disappointed  my children love to use it and i like the ability to monitor control what content they see with ease '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', str(sample))\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove extra space and tabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this product so far has not disappointed my children love to use it and i like the ability to monitor control what content they see with ease '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = re.sub('\\s+', ' ', str(sample))\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'product far disappointed children love use like ability monitor control content see ease'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_sentence = []\n",
    "# Stop word lists can be adjusted for your problem\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "# Tokenize the sentence\n",
    "words = word_tokenize(sample)\n",
    "for w in words:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    "sample = \" \".join(filtered_sentence)\n",
    "\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'product far disappoint children love use like abil monitor control content see eas'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the stemmer\n",
    "snow = SnowballStemmer('english')\n",
    "stemmed_sentence = []\n",
    "\n",
    "# Tokenize the sentence\n",
    "words = word_tokenize(sample)\n",
    "for w in words:\n",
    "    # Stem the word/token\n",
    "    stemmed_sentence.append(snow.stem(w))\n",
    "sample = \" \".join(stemmed_sentence)\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'product far disappoint child love use like abil monitor control content see ea'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the lemmatizer\n",
    "wl = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "lemmatized_sentence = []\n",
    "\n",
    "# Tokenize the sentence\n",
    "words = word_tokenize(sample)\n",
    "# Get position tags\n",
    "word_pos_tags = nltk.pos_tag(words)\n",
    "# Map the position tag and lemmatize the word/token\n",
    "for idx, tag in enumerate(word_pos_tags):\n",
    "    lemmatized_sentence.append(wl.lemmatize(tag[0], get_wordnet_pos(tag[1])))\n",
    "\n",
    "sample = \" \".join(lemmatized_sentence)\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data Preprocessing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sentence = []\n",
    "stemmed_sentence = []\n",
    "lemmatized_sentence = []\n",
    "stop_words = set(stopwords.words('english'))\n",
    "snow = SnowballStemmer('english')\n",
    "wl = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "\n",
    "for i in range (df.shape[0]):\n",
    "    Text = str(df.iloc[i,0])\n",
    "    Text = Text.lower()\n",
    "    Text = Text.strip()\n",
    "    Text = re.compile('<.*?>').sub('', Text)\n",
    "    Text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', Text)\n",
    "    Text = re.sub('\\s+', ' ', Text)\n",
    "    #tokenize\n",
    "    words = word_tokenize(Text)\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "    Text = \" \".join(filtered_sentence)\n",
    "    filtered_sentence.clear()\n",
    "    #stemming\n",
    "    words = word_tokenize(Text)\n",
    "    for w in words:\n",
    "        stemmed_sentence.append(snow.stem(w))\n",
    "    Text = \" \".join(stemmed_sentence)\n",
    "    stemmed_sentence.clear()\n",
    "    #Lemmatization\n",
    "    words = word_tokenize(Text)\n",
    "    # Get position tags\n",
    "    word_pos_tags = nltk.pos_tag(words)\n",
    "    # Map the position tag and lemmatize the word/token\n",
    "    for idx, tag in enumerate(word_pos_tags):\n",
    "        lemmatized_sentence.append(wl.lemmatize(tag[0], get_wordnet_pos(tag[1])))\n",
    "    Text = \" \".join(lemmatized_sentence)\n",
    "    lemmatized_sentence.clear()\n",
    "    df.iloc[i,0]=Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating label and Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['reviews.text']\n",
    "y = df['reviews.rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1.0\n",
       "1        1.0\n",
       "2        1.0\n",
       "3        1.0\n",
       "4        1.0\n",
       "        ... \n",
       "34655    0.0\n",
       "34656    0.0\n",
       "34657    0.0\n",
       "34658    0.0\n",
       "34659    0.0\n",
       "Name: reviews.rating, Length: 34626, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map class 1 , 2 as Negative (-1) ---- class 3 as Neutral (0) ---- class 4 , 5 as Positive (1)\n",
    "y[y==1]=0\n",
    "y[y==2]=0\n",
    "y[y==3]=0\n",
    "y[y==4]=1\n",
    "y[y==5]=1\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF - IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000s</th>\n",
       "      <th>01</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>0ff</th>\n",
       "      <th>0ghz</th>\n",
       "      <th>0ne</th>\n",
       "      <th>...</th>\n",
       "      <th>zigbe</th>\n",
       "      <th>zinio</th>\n",
       "      <th>zip</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zippi</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zwave</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34621</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34622</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34623</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34624</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34625</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34626 rows × 9439 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        00  000  000s   01   04   05   06  0ff  0ghz  0ne  ...  zigbe  zinio  \\\n",
       "0      0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  ...    0.0    0.0   \n",
       "1      0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  ...    0.0    0.0   \n",
       "2      0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  ...    0.0    0.0   \n",
       "3      0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  ...    0.0    0.0   \n",
       "4      0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  ...    0.0    0.0   \n",
       "...    ...  ...   ...  ...  ...  ...  ...  ...   ...  ...  ...    ...    ...   \n",
       "34621  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  ...    0.0    0.0   \n",
       "34622  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  ...    0.0    0.0   \n",
       "34623  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  ...    0.0    0.0   \n",
       "34624  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  ...    0.0    0.0   \n",
       "34625  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  ...    0.0    0.0   \n",
       "\n",
       "       zip  zipper  zippi  zombi  zone  zoo  zoom  zwave  \n",
       "0      0.0     0.0    0.0    0.0   0.0  0.0   0.0    0.0  \n",
       "1      0.0     0.0    0.0    0.0   0.0  0.0   0.0    0.0  \n",
       "2      0.0     0.0    0.0    0.0   0.0  0.0   0.0    0.0  \n",
       "3      0.0     0.0    0.0    0.0   0.0  0.0   0.0    0.0  \n",
       "4      0.0     0.0    0.0    0.0   0.0  0.0   0.0    0.0  \n",
       "...    ...     ...    ...    ...   ...  ...   ...    ...  \n",
       "34621  0.0     0.0    0.0    0.0   0.0  0.0   0.0    0.0  \n",
       "34622  0.0     0.0    0.0    0.0   0.0  0.0   0.0    0.0  \n",
       "34623  0.0     0.0    0.0    0.0   0.0  0.0   0.0    0.0  \n",
       "34624  0.0     0.0    0.0    0.0   0.0  0.0   0.0    0.0  \n",
       "34625  0.0     0.0    0.0    0.0   0.0  0.0   0.0    0.0  \n",
       "\n",
       "[34626 rows x 9439 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "texts = X\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(texts)\n",
    "features = vectorizer.transform(texts)\n",
    "\n",
    "X_N = pd.DataFrame(features.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "X_N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train_features is: (27700, 9439)\n",
      "Length of train_labels is: (27700,)\n",
      "Length of test_features is: (6926, 9439)\n",
      "Length of test_labels is: (6926,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get 80% of the data for training; the remaining 20% will be for validation and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_N, y, test_size=0.2,random_state=42)\n",
    "\n",
    "print(f\"Length of train_features is: {X_train.shape}\")\n",
    "print(f\"Length of train_labels is: {y_train.shape}\")\n",
    "print(f\"Length of test_features is: {X_test.shape}\")\n",
    "print(f\"Length of test_labels is: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:32:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  79,  356],\n",
       "       [  42, 6449]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "classifier_XGB = XGBClassifier()\n",
    "classifier_XGB.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred_XGB = classifier_XGB.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred_XGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9425353739532197"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred_XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score : 0.6271194235946982 \n",
      "Precision : 0.8002890436662395 \n",
      "Recall : 0.5875693488951103 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "print(\"F1-Score : {} \".format(f1_score(y_test, y_pred_XGB, average=\"macro\")))\n",
    "print(\"Precision : {} \".format(precision_score(y_test, y_pred_XGB, average=\"macro\")))\n",
    "print(\"Recall : {} \" .format(recall_score(y_test, y_pred_XGB, average=\"macro\")))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
